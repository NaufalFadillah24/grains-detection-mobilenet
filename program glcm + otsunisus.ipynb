{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edf337c-a7da-49aa-875e-d3041a83f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Import Library\n",
    "# =====================================================\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Reshape, Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2b2d29-e48d-4671-833d-21079a8d7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Load dataset dari folder\n",
    "# =====================================================\n",
    "def load_dataset(dataset_path):\n",
    "    images_gray = []\n",
    "    labels = []\n",
    "    classes = os.listdir(dataset_path)\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(dataset_path, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        for img_name in os.listdir(cls_path):\n",
    "            img_path = os.path.join(cls_path, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                clean = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "                images_gray.append(clean)\n",
    "                labels.append(cls)\n",
    "    return images_gray, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e142d7b-330f-4e66-988c-bc2797d2e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Fitur fisik dan GLCM\n",
    "# =====================================================\n",
    "def categorize_length_mm(length_mm):\n",
    "    if 6.5 <= length_mm < 7.0:\n",
    "        return \"pendek\"\n",
    "    elif 7.0 <= length_mm <= 8.5:\n",
    "        return \"panjang\"\n",
    "    else:\n",
    "        return \"lainnya\"\n",
    "\n",
    "def categorize_area_cm2(area_cm2):\n",
    "    if area_cm2 < 1.0:\n",
    "        return \"kecil\"\n",
    "    elif area_cm2 < 3.0:\n",
    "        return \"sedang\"\n",
    "    else:\n",
    "        return \"besar\"\n",
    "\n",
    "def extract_physical_features(img, pixels_per_cm, pixels_per_mm):\n",
    "    features = []\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area_cm2 = cv2.contourArea(cnt) / (pixels_per_cm**2)\n",
    "        perimeter_mm = cv2.arcLength(cnt, True) / pixels_per_mm\n",
    "        length_mm = h / pixels_per_mm\n",
    "        width_mm = w / pixels_per_mm\n",
    "    else:\n",
    "        area_cm2 = perimeter_mm = length_mm = width_mm = 0\n",
    "\n",
    "    features.extend([area_cm2, perimeter_mm, length_mm, width_mm])\n",
    "\n",
    "    area_mapping = {\"kecil\": [1,0,0], \"sedang\": [0,1,0], \"besar\": [0,0,1]}\n",
    "    features.extend(area_mapping[categorize_area_cm2(area_cm2)])\n",
    "\n",
    "    length_mapping = {\"pendek\": [1,0], \"panjang\": [0,1], \"lainnya\": [0,0]}\n",
    "    features.extend(length_mapping[categorize_length_mm(length_mm)])\n",
    "\n",
    "    glcm = graycomatrix(img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    features.extend([\n",
    "        graycoprops(glcm, 'contrast')[0,0],\n",
    "        graycoprops(glcm, 'dissimilarity')[0,0],\n",
    "        graycoprops(glcm, 'homogeneity')[0,0],\n",
    "        graycoprops(glcm, 'energy')[0,0],\n",
    "        graycoprops(glcm, 'correlation')[0,0]\n",
    "    ])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fd4269-961d-4d4f-8621-323d1e509610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Preprocessing gambar & CapsuleNet utility\n",
    "# =====================================================\n",
    "def preprocess_image(img, target_size=(224,224)):\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    img_resized = img_resized / 255.0\n",
    "    return img_resized\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "def create_capsule_layer(inputs, num_capsules=10, dim_capsule=16):\n",
    "    u = Conv2D(filters=num_capsules*dim_capsule, kernel_size=3, strides=2, padding='valid', activation='relu')(inputs)\n",
    "    u = Reshape(target_shape=[-1, dim_capsule])(u)\n",
    "    u = Lambda(squash)(u)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f46694-5644-4197-a2b7-b4ab7ab5f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Ekstraksi fitur MobileNet+CapsuleNet\n",
    "# =====================================================\n",
    "def extract_deep_features(images):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    capsule_features = create_capsule_layer(x)\n",
    "    features_model = Model(inputs=base_model.input, outputs=capsule_features)\n",
    "    deep_features = features_model.predict(images, verbose=0)\n",
    "    deep_features = deep_features.reshape(deep_features.shape[0], -1)\n",
    "    return deep_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bf6e7a-327e-414e-8ecc-f90933dc5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Gabungkan semua fitur\n",
    "# =====================================================\n",
    "def prepare_dataset(images_gray, labels, pixels_per_cm, pixels_per_mm):\n",
    "    images_rgb = np.array([preprocess_image(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)) for img in images_gray])\n",
    "    deep_feats = extract_deep_features(images_rgb)\n",
    "    phys_feats = np.array([extract_physical_features(img, pixels_per_cm, pixels_per_mm) for img in images_gray])\n",
    "    X = np.hstack([deep_feats, phys_feats])\n",
    "    y = np.array(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b252852-0ba0-483e-bf61-26696f3cd51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Training & Evaluasi Random Forest\n",
    "# =====================================================\n",
    "def train_random_forest(X_train, y_train, n_estimators=100):\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=np.unique(y_test)))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36e6009-362d-4ca1-9ae2-a2fbf27117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Fungsi Otsu & Otsu-Sinus\n",
    "# =====================================================\n",
    "def otsu_threshold(hist):\n",
    "    sum_total = np.dot(np.arange(256), hist)\n",
    "    best_t, max_sigma = 0, 0\n",
    "    w0, sum0 = 0.0, 0.0\n",
    "    for t in range(256):\n",
    "        w0 += hist[t]\n",
    "        sum0 += t * hist[t]\n",
    "        if w0 == 0 or w0 == 1:\n",
    "            continue\n",
    "        w1 = 1 - w0\n",
    "        mu0 = sum0 / w0\n",
    "        mu1 = (sum_total - sum0) / w1\n",
    "        sigma_b = w0 * w1 * (mu0 - mu1) ** 2\n",
    "        if sigma_b > max_sigma:\n",
    "            max_sigma, best_t = sigma_b, t\n",
    "    return best_t\n",
    "\n",
    "def otsu_sinus(hist):\n",
    "    sum_total = np.dot(np.arange(256), hist)\n",
    "    best_t, max_sigma = 0, 0\n",
    "    w0, sum0 = 0.0, 0.0\n",
    "    for t in range(256):\n",
    "        w0 += hist[t]\n",
    "        sum0 += t * hist[t]\n",
    "        if w0 == 0 or w0 == 1:\n",
    "            continue\n",
    "        w1 = 1 - w0\n",
    "        mu0 = sum0 / w0\n",
    "        mu1 = (sum_total - sum0) / w1\n",
    "        sigma_b = w0 * w1 * (math.sin(mu0 - mu1)) ** 2\n",
    "        if sigma_b > max_sigma:\n",
    "            max_sigma, best_t = sigma_b, t\n",
    "    return best_t\n",
    "\n",
    "def glcm_features(image):\n",
    "    glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                        symmetric=True, normed=True)\n",
    "    return {\n",
    "        \"contrast\": graycoprops(glcm, 'contrast').mean(),\n",
    "        \"correlation\": graycoprops(glcm, 'correlation').mean(),\n",
    "        \"energy\": graycoprops(glcm, 'energy').mean(),\n",
    "        \"homogeneity\": graycoprops(glcm, 'homogeneity').mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f0f816-147d-4d4b-ab79-9fa1cfdc95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Load Dataset ===\n",
      "Preparing features...\n",
      "WARNING:tensorflow:From C:\\Users\\Naufal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Split train/test...\n",
      "Training Random Forest...\n",
      "Evaluating model...\n",
      "Accuracy: 0.8340248962655602\n",
      "Confusion Matrix:\n",
      " [[75  1  5]\n",
      " [ 3 66 11]\n",
      " [ 9 11 60]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      INPARI       0.86      0.93      0.89        81\n",
      "        IR16       0.85      0.82      0.84        80\n",
      "   ROJO LELE       0.79      0.75      0.77        80\n",
      "\n",
      "    accuracy                           0.83       241\n",
      "   macro avg       0.83      0.83      0.83       241\n",
      "weighted avg       0.83      0.83      0.83       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Main Program\n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"C:/Users/Naufal/Downloads/gabungan\"\n",
    "    pixels_per_cm = 50\n",
    "    pixels_per_mm = pixels_per_cm / 10\n",
    "\n",
    "    print(\"=== Load Dataset ===\")\n",
    "    images_gray, labels = load_dataset(dataset_path)\n",
    "\n",
    "    print(\"Preparing features...\")\n",
    "    X, y = prepare_dataset(images_gray, labels, pixels_per_cm, pixels_per_mm)\n",
    "\n",
    "    print(\"Split train/test...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    print(\"Training Random Forest...\")\n",
    "    rf_model = train_random_forest(X_train, y_train)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "    # Demo Otsu & Otsu-Sinus untuk SEMUA gambar di folder\n",
    "    # -------------------------------------------------\n",
    "    folder_path = \"C:/Users/Naufal/Downloads/gabungan\"\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "        img_path = os.path.join(folder_path, file_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"âŒ {file_name} tidak bisa dibaca\")\n",
    "            continue\n",
    "\n",
    "        # === 1. Histogram ===\n",
    "        hist = cv2.calcHist([img], [0], None, [256], [0, 256]).ravel()\n",
    "        hist = hist / hist.sum()\n",
    "\n",
    "        # === 2. Hitung threshold Otsu & Otsu-Sinus ===\n",
    "        t_otsu = otsu_threshold(hist)\n",
    "        t_sin = otsu_sinus(hist)\n",
    "        print(f\"{file_name} -> Otsu: {t_otsu}, Otsu-Sinus: {t_sin}\")\n",
    "\n",
    "        _, th_otsu = cv2.threshold(img, t_otsu, 255, cv2.THRESH_BINARY)\n",
    "        _, th_sin = cv2.threshold(img, t_sin, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # === 3. Fitur GLCM ===\n",
    "        features_sin = glcm_features(th_sin.astype(np.uint8))\n",
    "        features_otsu = glcm_features(th_otsu.astype(np.uint8))\n",
    "        print(f\"ðŸ“Š {file_name} | GLCM Otsu-Sinus: {features_sin}\")\n",
    "        print(f\"ðŸ“Š {file_name} | GLCM Otsu: {features_otsu}\")\n",
    "\n",
    "        # === 4. Gabung threshold dengan GLCM ===\n",
    "        glcm_values = np.array(list(features_sin.values()))\n",
    "        glcm_norm = (glcm_values - glcm_values.min()) / (glcm_values.max() - glcm_values.min() + 1e-6)\n",
    "        glcm_weight = int((glcm_norm.mean() * 255))\n",
    "\n",
    "        _, th_glcm = cv2.threshold(img, int((t_sin + glcm_weight)/2), 255, cv2.THRESH_BINARY)\n",
    "        _, th_glcmotsu = cv2.threshold(img, int((t_otsu + glcm_weight)/2), 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        cleaned = cv2.morphologyEx(th_glcm, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "        # === 5. Plot hasil ===\n",
    "        titles = ['Original',\n",
    "                  f'Otsu (T={t_otsu})',\n",
    "                  f'Otsu-Sinus (T={t_sin})',\n",
    "                  f'Otsu-Sinus+GLCM (Tâ‰ˆ{int((t_sin+glcm_weight)/2)})',\n",
    "                  f'Otsu+GLCM (Tâ‰ˆ{int((t_otsu+glcm_weight)/2)})',\n",
    "                  'Otsu-Sinus+GLCM+Morphology']\n",
    "        images = [img, th_otsu, th_sin, th_glcm, th_glcmotsu, cleaned]\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        for i in range(len(images)):\n",
    "            plt.subplot(1, 6, i+1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.title(titles[i], fontsize=8)\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f\"Hasil thresholding: {file_name}\", fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebb6eb-70ef-48a7-9d47-85610c636dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
